@book{carmines_reliability_1979,
	title = {Reliability and Validity Assessment},
	isbn = {9780803913714},
	abstract = {This guide explains how social scientists can evaluate the reliability and validity of empirical measurements, discussing the three basic types of validity: criterion related, content, and construct. In addition, the paper shows how reliability is assessed by the retest method, alternative-forms procedure, split-halves approach, and internal consistency method.},
	language = {en},
	publisher = {{SAGE}},
	author = {Carmines, Edward G. and Zeller, Richard A.},
	month = nov,
	year = {1979},
	keywords = {Assessment, Measurement, Reliability, Validity}
}

@book{devellis_scale_2003,
	address = {Thousand Oaks, Calif.},
	title = {Scale development : theory and applications},
	abstract = {{'Scale} Development' guides the reader toward the identification of the latent variable, the generation of an item pool, the format for measurement \& the optimization of the scale length. Using exercises to illustrate the concepts, the text also includes advice about factor analytic strategies.},
	publisher = {Sage Publications},
	author = {{DeVellis}, Robert F},
	year = {2003},
	keywords = {Measurement, {NORC}, Psychometrics, Questionnaire Design, Questionnaire Validation, Scale development}
}

@book{devellis_scale_2003,
	address = {Thousand Oaks, Calif.},
	edition = {2nd Ed.},
	title = {Scale development : theory and applications},
	shorttitle = {Scale development},
	abstract = {{'Scale} Development' guides the reader toward the identification of the latent variable, the generation of an item pool, the format for measurement \& the optimization of the scale length. Using exercises to illustrate the concepts, the text also includes advice about factor analytic strategies.},
	publisher = {Sage Publications},
	author = {{DeVellis}, Robert F},
	year = {2003},
	keywords = {Measurement, Validity, Psychometrics, Questionnaire Design, Questionnaire Validation, Scale development}
},
@article{messick_validity_1995,
	title = {Validity of psychological assessment: Validation of inferences from persons' responses and performances as scientific inquiry into score meaning},
	volume = {50},
	doi = {10.1037/0003-066X.50.9.741},
	abstract = {The traditional conception of validity divides it into three separate and substitutable types: content, criterion, and construct validities. This view is fragmented and incomplete, especially because it fails to take into account both evidence of the value implications of score meaning as a basis for action and the social consequences of score use. The new unified concept of validity interrelates these issues as fundamental aspects of a more comprehensive theory of construct validity that addresses both score meaning and social values in test interpretation and test use. That is, unified validity integrates considerations of content, criteria, and consequences into a construct framework for the empirical testing of rational hypotheses about score meaning and theoretically relevant relationships, including those of an applied and a scientific nature. Six distinguishable aspects of construct validity are highlighted as a means of addressing central issues implicit in the notion of validity as a unified concept. These are content, substantive, structural, generalizability, external , and consequential aspects of construct validity. In effect, these six aspects function as general validity criteria or standards for all educational and psychological measurement, including performance assessments, which are discussed in some detail because of their increasing emphasis in educational and employment settings. ({PsycINFO} Database Record (c) 2010 {APA}, all rights reserved)},
	number = {9},
	journal = {American Psychologist},
	author = {Messick, Samuel},
	year = {1995},
	keywords = {Validity, Psychometrics},
	pages = {741--749}
},
@article{hood_validity_2009,
	title = {Validity in Psychological Testing and Scientific Realism},
	volume = {19},
	doi = {10.1177/0959354309336320},
	abstract = {Recent work in the conceptual foundations of psychometrics has concerned the question of validity. Borsboom and colleagues have challenged what they claim is the dominant theory of validity, that of Samuel Messick. In this paper I present Borsboom et al.’s concept of validity as a property of measurement instruments as well as Messick’s concept of validity as a property of interpretive inferences. I then relate their concepts of validity to scientific realism in the philosophy of science. I argue that there can be valid psychometric tests, in Borsboom et al.’s sense, only if some version of scientific realism is true. I argue that in Borsboom et al.’s and Messick’s approaches to validity, one finds the essential ingredients for a realist philosophy of science in psychological assessment. Borsboom et al. contribute semantic and ontological components while Messick provides the methodological tools for constructing an epistemology of psychological measurement. Though Borsboom et al. present their approach as an alternative to Messick’s, these two approaches to validity are potentially complementary.},
	number = {4},
	journal = {Theory \& Psychology},
	author = {Hood, S. Brian},
	month = aug,
	year = {2009},
	keywords = {Measurement, philosophy, Philosophy of Science, Psychometrics, theory, Validity},
	pages = {451--473}
},

