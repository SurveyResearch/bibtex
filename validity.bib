
@article{cicourel_interviews_1982,
	title = {Interviews, Surveys, and the Problem of Ecological Validity},
	volume = {17},
	url = {http://www.jstor.org/stable/27702491},
	abstract = {Despite the fact that virtually all social science data are derived from some kind of discourse or textual materials, sociologists have devoted little time to establishing explicit theoretical foundations for the use of such instruments as interviews and surveys. A key problem always has been the lack of clear theoretical concepts about the interpretation of interview and survey question and answer frames. We lack a theory of comprehension and communication that can provide a foundation for the way that question-answer systems function, and the way respondents understand them. The paper briefly describes the possible relevance of linguistic and cognitive processes for improving our understanding of interviews and surveys. The theoretical foundations of interviews and surveys also must address the way that artificial circumstances become necessary to guarantee adequate study designs. These artificial circumstances often violate ecological validity, or the way interviews and survey questions are constructed, understood, and answered, as contrasted with the way that field notes and tape-recordings of natural settings are used to address the same or comparable substantive and theoretical issues.},
	number = {1},
	urldate = {2012-03-11},
	journal = {The American Sociologist},
	author = {Cicourel, Aaron V.},
	month = feb,
	year = {1982},
	keywords = {Ecological Validity, Interviews, Survey Research, Validity},
	pages = {11--20}
}
@article{embretson_construct_2007,
	title = {Construct Validity: A Universal Validity System or Just Another Test Evaluation Procedure?},
	volume = {36},
	shorttitle = {Construct Validity},
	doi = {10.3102/0013189X07311600},
	abstract = {Lissitz and Samuelsen (2007) have proposed a framework that seemingly deems construct validity evidence irrelevant to supporting educational test meaning. The author of this article agrees with Lissitz and Samuelsen that internal evidence establishes test meaning, but she argues that construct validity need not be removed from the validity sphere. In fact, she argues that doing so could have an adverse impact on the quality of educational tests. She proposes a universal system for construct validity to illustrate how diverse evidence is relevant to claims about measuring examinees' knowledge, skills, abilities, and competencies even when test specifications provide a major source of evidence.},
	number = {8},
	journal = {Educational Researcher},
	author = {Embretson, Susan E.},
	month = nov,
	year = {2007},
	keywords = {Construct validity, Validity},
	pages = {449--455}
},

@article{gorin_reconsidering_2007,
	title = {Reconsidering Issues in Validity Theory},
	volume = {36},
	url = {http://www.jstor.org/stable/4621100},
	doi = {10.2307/4621100},
	abstract = {Lissitz and Samuelsen (2007) propose a new framework for validity theory and terminology, emphasizing a shift in the and practice toward issues of test content rather than constructs. The author of this article argues that several of Lissitz and Samuelsen's critiques of validity theory focus on previously considered, but subsequently discarded, validity conceptualizations. In addition, she suggests that Lissitz and Samuelsen's conceptualization returns to methods shown historically to be problematic for score use and interpretation. In doing so, she highlights developments in validity theory and practice centering on cognitively based examinations of test scores that have contributed to increased understanding of score meaning and stronger validity arguments.},
	number = {8},
	urldate = {2013-01-27},
	journal = {Educational Researcher},
	author = {Gorin, Joanna S.},
	month = nov,
	year = {2007},
	keywords = {Psychometrics, Validity},
	pages = {456--462}
},

@article{hood_validity_2009,
	title = {Validity in Psychological Testing and Scientific Realism},
	volume = {19},
	doi = {10.1177/0959354309336320},
	abstract = {Recent work in the conceptual foundations of psychometrics has concerned the question of validity. Borsboom and colleagues have challenged what they claim is the dominant theory of validity, that of Samuel Messick. In this paper I present Borsboom et al.’s concept of validity as a property of measurement instruments as well as Messick’s concept of validity as a property of interpretive inferences. I then relate their concepts of validity to scientific realism in the philosophy of science. I argue that there can be valid psychometric tests, in Borsboom et al.’s sense, only if some version of scientific realism is true. I argue that in Borsboom et al.’s and Messick’s approaches to validity, one finds the essential ingredients for a realist philosophy of science in psychological assessment. Borsboom et al. contribute semantic and ontological components while Messick provides the methodological tools for constructing an epistemology of psychological measurement. Though Borsboom et al. present their approach as an alternative to Messick’s, these two approaches to validity are potentially complementary.},
	number = {4},
	journal = {Theory \& Psychology},
	author = {Hood, S. Brian},
	month = aug,
	year = {2009},
	keywords = {Measurement, philosophy, Philosophy of Science, Psychometrics, theory, Validity},
	pages = {451--473}
}

@article{hood_defense_2012,
	title = {In Defense of an Instrument-Based Approach to Validity},
	volume = {10},
	issn = {1536-6367},
	doi = {10.1080/15366367.2012.681976},
	number = {1-2},
	journal = {Measurement: Interdisciplinary Research \& Perspective},
	author = {Hood, S. Brian},
	year = {2012},
	keywords = {Validity},
	pages = {63--65}
},

@article{lissitz_validity_2012,
	title = {Validity is an Action Verb: Commentary on: {“Clarifying} the Consensus Definition of Validity”},
	volume = {10},
	shorttitle = {Validity is an Action Verb},
	doi = {10.1080/15366367.2012.677346},
	number = {1-2},
	journal = {Measurement: Interdisciplinary Research \& Perspective},
	author = {Lissitz, Robert W. and Caliço, Tiago},
	year = {2012},
	keywords = {Validity},
	pages = {75--79}
},

@article{lissitz_suggested_2007,
	title = {A Suggested Change in Terminology and Emphasis regarding Validity and Education},
	volume = {36},
	doi = {10.3102/0013189X07311286},
	abstract = {This article raises a number of questions about the current unified theory of test validity that has construct validity at its center. The authors suggest a different way of conceptualizing the problem of establishing validity by considering whether the focus of the investigation of a test is internal to the test itself or focuses on constructs and relationships that are external to the test. They also consider whether the perspective on the test examination is theoretical or practical. The resulting taxonomy, encompassing both investigative focus and perspective, serves to organize a reconceptualization of the field of validity studies. The authors argue that this approach, together with changes in the rest of the terminology regarding validity, leads to a more understandable and usable model.},
	number = {8},
	journal = {Educational Researcher},
	author = {Lissitz, Robert W. and Samuelsen, Karen},
	month = nov,
	year = {2007},
	keywords = {Special Issue, Validity},
	pages = {437--448}
},

@article{lissitz_further_2007,
	title = {Further Clarification regarding Validity and Education},
	volume = {36},
	doi = {10.3102/0013189X07311612},
	number = {8},
	journal = {Educational Researcher},
	author = {Lissitz, Robert W. and Samuelsen, Karen},
	month = nov,
	year = {2007},
	keywords = {Psychometrics, Validity},
	pages = {482--484}
},

@article{messick_test_1998,
	title = {Test Validity: A Matter of Consequence},
	volume = {45},
	shorttitle = {Test Validity},
	doi = {10.1023/A:1006964925094},
	abstract = {In this note I comment briefly on Keith Markus's illuminating article on {“Science}, measurement, and validity: Is completion of Samuel Messick's synthesis possible?” Markus's analysis bears directly on the controversial status of the consequential basis of test validity in relation to the more traditional evidential basis. After addressing some key points in his argument, I then comment more generally on sources of the controversy over the claim that empirical consequences of test interpretation and use constitute validity evidence.},
	number = {1-3},
	journal = {Social Indicators Research},
	author = {Messick, Samuel},
	month = nov,
	year = {1998},
	keywords = {Microeconomics, Sociology, Test theory, Validity},
	pages = {35--44}
}

@article{messick_validity_1995,
	title = {Validity of psychological assessment: Validation of inferences from persons' responses and performances as scientific inquiry into score meaning},
	volume = {50},
	doi = {10.1037/0003-066X.50.9.741},
	abstract = {The traditional conception of validity divides it into three separate and substitutable types: content, criterion, and construct validities. This view is fragmented and incomplete, especially because it fails to take into account both evidence of the value implications of score meaning as a basis for action and the social consequences of score use. The new unified concept of validity interrelates these issues as fundamental aspects of a more comprehensive theory of construct validity that addresses both score meaning and social values in test interpretation and test use. That is, unified validity integrates considerations of content, criteria, and consequences into a construct framework for the empirical testing of rational hypotheses about score meaning and theoretically relevant relationships, including those of an applied and a scientific nature. Six distinguishable aspects of construct validity are highlighted as a means of addressing central issues implicit in the notion of validity as a unified concept. These are content, substantive, structural, generalizability, external , and consequential aspects of construct validity. In effect, these six aspects function as general validity criteria or standards for all educational and psychological measurement, including performance assessments, which are discussed in some detail because of their increasing emphasis in educational and employment settings.},
	number = {9},
	journal = {American Psychologist},
	author = {Messick, Samuel},
	year = {1995},
	keywords = {Validity},
	pages = {741--749}
}

@article{mislevy_case_2012,
	title = {The Case for Informal Argument},
	volume = {10},
	doi = {10.1080/15366367.2012.682525},
	number = {1-2},
	urldate = {2013-01-24},
	journal = {Measurement: Interdisciplinary Research \& Perspective},
	author = {Mislevy, Robert J.},
	year = {2012},
	keywords = {Validity},
	pages = {93--96}
},

@article{mislevy_validity_2007,
	title = {Validity by Design},
	volume = {36},
	doi = {10.3102/0013189X07311660},
	abstract = {Lissitz and Samuelsen (2007) argue that the unitary conception of validity for educational assessments is too broad to guide applied work. They call for attention to considerations and procedures that focus on ``test development and analysis of the test itself'' and propose that those activities be collectively termed content validity. The author of this article describes work that makes more explicit the underlying principles of assessment design, thereby providing conceptual foundations for familiar practices and supporting the development of new ones. By structuring design activities around assessment arguments, the test developer accrues evidence in passing for what Embretson (1983) calls "construct representation" argumentation for validity.},
	number = {8},
	journal = {Educational Researcher},
	author = {Mislevy, Robert J.},
	month = nov,
	year = {2007},
	pages = {463--469}
},

@article{moss_reconstructing_2007,
	title = {Reconstructing Validity},
	volume = {36},
	doi = {10.3102/0013189X07311608},
	abstract = {In response to Lissitz and Samuelsen (2007), the author reconstructs the historical arguments for the more comprehensive unitary concept of validity and the principles of scientific inquiry underlying it. Her response is organized in terms of four questions: (a) How did validity in educational measurement come to be conceptualized as unitary, and why? (b) What is construct validity, and how does it provide the basis for a unitary concept of validity? (c) Why has the focus of validity been on the interpretations and uses of test scores rather than on the test itself? and (d) What sort of guidance for test developers and evaluators has been provided within a unitary concept of validity, and how might it be enhanced? The author highlights the role that cases of programmatic validity research can play in representing validity theory and guiding validity inquiry.},
	number = {8},
	journal = {Educational Researcher},
	author = {Moss, Pamela A.},
	month = nov,
	year = {2007},
	keywords = {Psychometrics, Validity},
	pages = {470--476}
},

@article{moss_recovering_1998,
	title = {Recovering a Dialectical View of Rationality},
	volume = {45},
	doi = {10.1023/A:1006925226003},
	abstract = {In this article, I argue for an interpretation of Messick's (1989) theory of validity that supports a dialectical over a technical view of rationality in making validity judgments. A primary theme underlying Messick's theory is the {"Singerian"} approach to inquiry where one system of inquiry is observed by another in order to open "their underlying scientific and value assumptions to public scrutiny and critique" (pp. 61-62). Against Markus (this issue), who argues that a "completion" of Messick's theoretical project is necessary to support a single, best justified validity judgment for any given test use, I argue that Messick has provided a means of maintaining validity theory and the judgments it supports as ongoing accomplishments, always open to other perspectives, and critically reflexive in light of those challenges.},
	number = {1/3},
	journal = {Social Indicators Research},
	author = {Moss, Pamela A.},
	month = nov,
	year = {1998},
	keywords = {Validity},
	pages = {55--67}
},

@article{newton_clarifying_2012,
	title = {Clarifying the Consensus Definition of Validity},
	volume = {10},
	doi = {10.1080/15366367.2012.669666},
	abstract = {The 1999 Standards for Educational and Psychological Testing defines validity as the degree to which evidence and theory support the interpretations of test scores entailed by proposed uses of tests. Although quite explicit, there are ways in which this definition lacks precision, consistency, and clarity. The history of validity has taught us that ambiguity risks oversimplification, misunderstanding, inadequate validation, and the inevitable potential for inappropriate interpretation and use of results. This article identifies ways in which the spirit of the Standards can be clarified, with the intention of reducing these risks. The article provides an elaboration of the consensus definition, invoking a narrow, technical sense of validity, unique to the professions of educational and psychological measurement and assessment; an assessment-based decision-making procedure is valid if the argument for interpreting assessment outcomes (under stated conditions and in terms of stated conclusions) as measures of the attribute entailed by the decision is sufficiently strong.},
	number = {1-2},
	journal = {Measurement: Interdisciplinary Research \& Perspective},
	author = {Newton, Paul E.},
	year = {2012},
	keywords = {Educational Testing, Psychological Testing, Testing, Validity},
	pages = {1--29}
},

@article{newton_questioning_2012,
	title = {Questioning the Consensus Definition of Validity},
	volume = {10},
	doi = {10.1080/15366367.2012.688456},
	number = {1-2},
	journal = {Measurement: Interdisciplinary Research \& Perspective},
	author = {Newton, Paul E.},
	year = {2012},
	keywords = {Validity},
	pages = {110--122}
},

@article{reckase_interaction_1998,
	title = {The Interaction of Values and Validity Assessment: Does a Test's Level of Validity Depend on a Researcher's Values?},
	volume = {45},
	shorttitle = {The Interaction of Values and Validity Assessment},
	doi = {10.1023/A:1006973109164},
	abstract = {This paper presents a somewhat different framework for considering the validity problem than that proposed by Messick (1989). Validity evaluation is considered as a problem of comparing continua in a multidimensional space corresponding to constructs, tests, and applications. This framework is used to consider the position taken by Markus (1998) and to argue that a test's validity is independent of a researcher's values, and that a completion of Messick's synthesis is not needed.},
	number = {1-3},
	journal = {Social Indicators Research},
	author = {Reckase, Mark D.},
	month = nov,
	year = {1998},
	keywords = {Microeconomics, multidimensional item response theory, Public {Health/Gesundheitswesen}, Quality of Life Research, reference composite, Sociology, test development, Validity},
	pages = {45--54}
},

@article{sireci_validity_2007,
	title = {On Validity Theory and Test Validation},
	volume = {36},
	doi = {10.3102/0013189X07311609},
	abstract = {Lissitz and Samuelsen (2007) propose a new framework for conceptualizing test validity that separates analysis of test properties from analysis of the construct measured. In response, the author of this article reviews fundamental characteristics of test validity, drawing largely from seminal writings as well as from the accepted standards. He argues that a serious validation endeavor requires integration of construct theory, subjective analysis of test content, and empirical analysis of item and test score data. He argues that the proposals presented by Lissitz and Samuelsen require revision or clarification to be useful to practitioners for justifying the use of a test for a particular purpose. He discusses the strengths and limitations of their proposal, as well as major tenets from other validity perspectives.},
	number = {8},
	journal = {Educational Researcher},
	author = {Sireci, Stephen G.},
	month = nov,
	year = {2007},
	keywords = {Psychometrics, Validity},
	pages = {477--481}
}

@article{sireci_construct_1998,
	title = {The Construct of Content Validity},
	volume = {45},
	doi = {10.1023/A:1006985528729},
	abstract = {Many behavioral scientists argue that assessments used in social indicators research must be content-valid. However, the concept of content validity has been controversial since its inception. The current unitary conceptualization of validity argues against use of the term content validity, but stresses the importance of content representation in the instrument construction and evaluation processes. However, by arguing against use of this term, the importance of demonstrating content representativeness has been severely undermined. This paper reviews the history of content validity theory to underscore its importance in evaluating construct validity. It is concluded that although measures cannot be “validated” based on content validity evidence alone, demonstration of content validity is a fundamental requirement of all assessment instruments.},
	number = {1-3},
	journal = {Social Indicators Research},
	author = {Sireci, Stephen G.},
	month = nov,
	year = {1998},
	keywords = {Microeconomics, Quality of Life Research, Sociology, Validity},
	pages = {83--117}
}