@incollection{ericsson_protocol_223,
	address = {Cambridge, {UK}},
	title = {Protocol analysis and expert thought: Concurrent verbalizations of thinking during experts' performance on representative task.},
	booktitle = {Cambridge handbook of expertise and expert performance},
	publisher = {Cambridge University Press},
	author = {Ericsson, K. Anders},
	year = {223},
	keywords = {Protocol Analysis}
},

@article{ericsson_verbal_1980,
	title = {Verbal Reports as Data.},
	volume = {87},
	url = {http://www.eric.ed.gov/ERICWebPortal/detail?accno=EJ231273},
	abstract = {Accounting for verbal reports requires explication of the mechanisms by which the reports are generated and influenced by experimental factors. We discuss different cognitive processes underlying verbalization and present a model of how subjects, when asked to think aloud, verbalize information from their short-term memory. {(Author/GDC)}},
	number = {3},
	journal = {Psychological Review},
	author = {Ericsson, K. Anders and Simon, Herbert A.},
	month = may,
	year = {1980},
	keywords = {Behavioral Science Research, Cognitive Processes, data analysis, Data Collection, Literature Reviews, Memory, Protocol Analysis, Questioning Techniques, Research Methodology, Research Problems, Short Term Memory, Speech Communication, Verbal Reports},
	pages = {215--51}
}
@article{nisbett_culture_2001,
	title = {Culture and systems of thought: holistic versus analytic cognition},
	volume = {108},
	%issn = {{0033-295X}},
	shorttitle = {Culture and systems of thought},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/11381831},
	abstract = {The authors find East Asians to be holistic, attending to the entire field and assigning causality to it, making relatively little use of categories and formal logic, and relying on "dialectical" reasoning, whereas Westerners are more analytic, paying attention primarily to the object and the categories to which it belongs and using rules, including formal logic, to understand its behavior. The 2 types of cognitive processes are embedded in different naive metaphysical systems and tacit epistemologies. The authors speculate that the origin of these differences is traceable to markedly different social systems. The theory and the evidence presented call into question long-held assumptions about basic cognitive processes and even about the appropriateness of the process-content distinction.},
	number = {2},
	journal = {Psychological Review},
	author = {Nisbett, R E and Peng, K and Choi, I and Norenzayan, A},
	month = apr,
	year = {2001},
	note = {{PMID:} 11381831},
	keywords = {Asia, Southeastern, Attitude to Health, {Cross-Cultural} Comparison, Cross-cultural Psychology, Cross-cultural research, Holistic Health, Humans, Knowledge, metaphysics},
	pages = {291--310}
},

@article{nisbett_influence_2005,
	title = {The influence of culture: holistic versus analytic perception},
	volume = {9},
	%issn = {1364-6613},
	shorttitle = {The influence of culture},
	%url = {http://www.ncbi.nlm.nih.gov/pubmed/16129648},
	doi = {10.1016/j.tics.2005.08.004},
	abstract = {There is recent evidence that perceptual processes are influenced by culture. Westerners tend to engage in context-independent and analytic perceptual processes by focusing on a salient object independently of its context, whereas Asians tend to engage in context-dependent and holistic perceptual processes by attending to the relationship between the object and the context in which the object is located. Recent research has explored mechanisms underlying such cultural differences, which indicate that participating in different social practices leads to both chronic as well as temporary shifts in perception. These findings establish a dynamic relationship between the cultural context and perceptual processes. We suggest that perception can no longer be regarded as consisting of processes that are universal across all people at all times.},
	number = {10},
	journal = {Trends in Cognitive Sciences},
	author = {Nisbett, Richard E and Miyamoto, Yuri},
	month = oct,
	year = {2005},
	note = {{PMID:} 16129648},
	keywords = {Attention, cognition, {Cross-Cultural} Comparison, Culture, Humans, Neuropsychological Tests, Perception, Psychology, Visual Perception},
	pages = {467--473}
},

@article{nisbett_verbal_1977,
	title = {Verbal reports about causal influences on social judgments: Private access versus public theories},
	volume = {35},
	%issn = {{1939-1315(Electronic);0022-3514(Print)}},
	shorttitle = {Verbal reports about causal influences on social judgments},
	doi = {10.1037/0022-3514.35.9.613},
	abstract = {128 female Ss were asked to make 4 judgments about a young woman after reading her "job application portfolio." Five characteristics of the young woman were manipulated orthogonally (e.g., physical appearance and academic credentials). Ss were asked to report how each of the 5 manipulated factors had influenced each of their judgments. {"Observer} Ss," who had access only to very impoverished descriptions of each of the 5 factors, were asked to predict how each of the factors would influence each of the judgments. Results show that (a) S reports about the effects of the factors on the judgments were in general highly inaccurate; (b) observer predictions were extremely similar to S reports; (c) for the single judgment for which Ss showed substantial accuracy (a judgment about intelligence), observer predictions were as accurate as S reports. Results indicate that whatever introspective access to cognitive processes may exist, it is not sufficient to produce generally accurate reports about such processes, nor even to produce reports that differ much from those of poorly informed outside observers. {(PsycINFO} Database Record (c) 2012 {APA}, all rights reserved)},
	number = {9},
	journal = {Journal of Personality and Social Psychology},
	author = {Nisbett, Richard E. and Bellows, Nancy},
	year = {1977},
	keywords = {Cognitive Interviewing, Protocol Analysis, Verbal Reports},
	pages = {613--624}
},

@article{nisbett_telling_1977,
	title = {Telling more than we can know: Verbal reports on mental processes},
	volume = {84},
	%issn = {{1939-1471(Electronic);0033-295X(Print)}},
	shorttitle = {Telling more than we can know},
	doi = {10.1037/0033-295X.84.3.231},
	abstract = {Reviews evidence which suggests that there may be little or no direct introspective access to higher order cognitive processes. Ss are sometimes (a) unaware of the existence of a stimulus that importantly influenced a response, (b) unaware of the existence of the response, and (c) unaware that the stimulus has affected the response. It is proposed that when people attempt to report on their cognitive processes, that is, on the processes mediating the effects of a stimulus on a response, they do not do so on the basis of any true introspection. Instead, their reports are based on a priori, implicit causal theories, or judgments about the extent to which a particular stimulus is a plausible cause of a given response. This suggests that though people may not be able to observe directly their cognitive processes, they will sometimes be able to report accurately about them. Accurate reports will occur when influential stimuli are salient and are plausible causes of the responses they produce, and will not occur when stimuli are not salient or are not plausible causes. (86 ref) {(PsycINFO} Database Record (c) 2012 {APA}, all rights reserved)},
	number = {3},
	journal = {Psychological Review},
	author = {Nisbett, Richard E. and Wilson, Timothy D.},
	year = {1977},
	keywords = {Cognitive Interviewing, Protocol Analysis, Verbal Reports},
	pages = {231--259}
}
@article{beatty_research_2007,
	title = {Research Synthesis: The Practice of Cognitive Interviewing},
	volume = {71},
	shorttitle = {Research Synthesis},
	%url = {http://poq.oxfordjournals.org/content/71/2/287.abstract},
	doi = {10.1093/poq/nfm006},
	abstract = {Cognitive interviewing has emerged as one of the more prominent methods for identifying and correcting problems with survey questions. We define cognitive interviewing as the administration of draft survey questions while collecting additional verbal information about the survey responses, which is used to evaluate the quality of the response or to help determine whether the question is generating the information that its author intends. But beyond this general categorization, cognitive interviewing potentially includes a variety of activities that may be based on different assumptions about the type of data that are being collected and the role of the interviewer in that process. This synthesis reviews the range of current cognitive interviewing practices, focusing on three considerations: (1) what are the dominant paradigms of cognitive interviewing—what is produced under each, and what are their apparent advantages; (2) what key decisions about cognitive interview study design need to be made once the general approach is selected (e.g., who should be interviewed, how many interviews should be conducted, and how should probes be selected), and what bases exist for making these decisions; and (3) how cognitive interviewing data should be evaluated, and what standards of evidence exist for making questionnaire design decisions based on study findings. In considering these issues, we highlight where standards for best practices are not clearly defined, and suggest broad areas worthy of additional methodological research.},
	number = {2},
	journal = {Public Opinion Quarterly},
	author = {Beatty, Paul C. and Willis, Gordon B.},
	month = jun,
	year = {2007},
	keywords = {Cognitive Interviewing, {NORC}, Questionnaire Testing, Survey Methodology},
	pages = {287 --311}
},

@inproceedings{blair_methods_2010,
	address = {Vancouver, {BC}},
	title = {Methods for the Analysis of Cognitive Interviews},
	abstract = {Cognitive interviewing has become a predominant method of survey question pretesting. Despite the stature that cognitive interviewing enjoys as an established and respected pretesting method, there is little consensus on the ways in which the verbal reports should be handled or how the analysis should be conducted. Nor is there a widely accepted notion of what comprises “evidence” from a cognitive session. In many important ways, cognitive interviewing has evolved from and become different from the original think aloud and verbal protocol methodologies of cognitive psychology. We revisit the original think aloud and verbal protocol methodology and examine how current question pretesting practices align with the original goals and limitations of the think aloud method.},
	booktitle = {{JSM} 2010 Proceedings},
	author = {Blair, Johnny and Brick, Pat Dean},
	year = {2010},
	keywords = {Cognitive Interviewing, {NORC}},
	pages = {3739--3748}
},

@article{collins_pretesting_2003,
	title = {Pretesting Survey Instruments: An Overview of Cognitive Methods},
	volume = {12},
	%issn = {0962-9343},
	shorttitle = {Pretesting Survey Instruments},
	url = {http://www.jstor.org/stable/4038871},
	abstract = {This article puts forward the case that survey questionnaires, which are a type of measuring instrument, can and should be tested to ensure they meet their purpose. Traditionally survey researchers have been pre-occupied with 'standardising' data collection instruments and procedures such as question wording and have assumed that experience in questionnaire design, coupled with pilot testing of questionnaires, will then ensure valid and reliable results. However, implicit in the notion of standardisation are the assumptions that respondents are able to understand the questions being asked, that questions are understood in the same way by all respondents, and that respondents are willing and able to answer such questions. The development of cognitive question testing methods has provided social researchers with a number of theories and tools to test these assumptions, and to develop better survey instruments and questionnaires. This paper describes some of these theories and tools, and argues that cognitive testing should be a standard part of the development process of any survey instrument.},
	number = {3},
	journal = {Quality of Life Research},
	author = {Collins, Debbie},
	month = may,
	year = {2003},
	note = {{ArticleType:} research-article / Full publication date: May, 2003 / Copyright © 2003 Springer},
	keywords = {Cognitive Interviewing, Questionnaire Testing},
	pages = {229--238}
},

@article{conrad_sources_2009,
	title = {Sources of Error in Cognitive Interviews},
	volume = {73},
	%issn = {{0033-362X}, 1537-5331},
	%url = {http://poq.oxfordjournals.org/content/73/1/32},
	doi = {10.1093/poq/nfp013},
	abstract = {Cognitive interviewing is used to identify problems in questionnaires under development by asking a small number of pretest participants to verbally report their thinking while answering the draft questions. Just as responses in production interviews include measurement error, so the detection of problems in cognitive interviews can include error. In the current study, we examine error in the problem detection of both cognitive interviewers evaluating their own interviews and independent judges listening to the full set of interviews. The cognitive interviewers were instructed to probe for additional information in one of two ways: the Conditional Probe group was instructed to probe only about what respondents had explicitly reported; the Discretionary Probe group was instructed to probe whenever they felt it appropriate. Agreement about problems was surprisingly low overall, but differed by interviewing technique. The Conditional Probe interviewers uncovered fewer potential problems but with higher inter-judge reliability than did the Discretionary Probe interviewers. These differences in reliability were related to the type of probes. When interviewers in either group probed beyond the content of respondents’ verbal reports, they were prone to believe that the respondent had experienced a problem when the majority of judges did not believe this to be the case (false alarms). Despite generally poor performance at the level of individual verbal reports, judges reached relatively consistent conclusions across the interviews about which questions most needed repair. Some practical measures may improve the conclusions drawn from cognitive interviews but the quality of the findings is limited by the content of the verbal reports.},
	number = {1},
	journal = {Public Opinion Quarterly},
	author = {Conrad, Frederick G and Blair, Johnny},
	month = mar,
	year = {2009},
	keywords = {Cognitive Interviewing, Verbal Reports},
	pages = {32--55}
}
@incollection{willis_cognitive_2004,
	title = {Cognitive Interviewing Revisited: A Useful Technique, in Theory?},
	shorttitle = {Cognitive Interviewing Revisited},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/0471654728.ch2/summary},
	abstract = {In this chapter we adopt a more theoretic viewpoint relating to the development, testing, and evaluation of survey questions, stemming from the perspective commonly termed {CASM} (cognitive aspects of survey methodology). We examine two theoretical orientations that apply to cognitive interviewing and conclude that both are in current form somewhat limited in directing these practices.},
	%urldate = {2012-12-23},
	booktitle = {Methods for Testing and Evaluating Survey Questionnaires},
	crossref = {presser_methods_book_2004},
	publisher = {John Wiley \& Sons, Inc.},
	author = {Willis, Gordon B.},
	editor = {Presser, Stanley and Rothgeb, Jennifer M. and Couper, Mick P. and Lessler, Judith T. and Elizabethrtin and Jeanrtin and Singer, Eleanor},
	year = {2004},
	keywords = {cognitive interviewing, definition, Ericsson, Simon, survey response process, task analysis, theory, useful technique, verbal reports},
	pages = {23–43}
}
@incollection{conrad_aspects_2004,
	address = {New York},
	title = {Aspects of data quality in cognitive interviews: The case of verbal reports},
	abstract = {Cognitive interview techniques are constructed from a menu of laboratory procedures leading to
many disparate techniques. However, one common thread across techniques is that they all produce verbal reports. It stands to reason that different versions of cognitive interviewing produce data and decisions that vary in their quality, but very little empirical evaluation has been conducted.
We propose a research agenda for evaluating the quality of information produced by cognitive interview techniques. We propose that problem detection and, ultimately, problem repair are the fundamental purposes of the method. The quality of each should be assessed through standalone experiments that measure reliability and validity of potential problems and effectiveness of revisions in eliminating recurrence of problems.
We then illustrate the kind of research we advocate with a case study that compares quality of the verbal reports in two cognitive interview techniques. One technique represents the practices of experienced cognitive interviewers. The other technique constrains interviewer probing to explicit indications of problems in respondents’ verbal reports. The results suggest that, in cognitive interviewing in general, verbal reports about answering survey questions are difficult to interpret consistently, raising concerns about their credibility. They further suggest that constraining probes to specific respondent indications of problems leads to fewer but more reliably identified problems.},
	booktitle = {Questionnaire Development, Evaluation and Testing Methods},
	publisher = {John Wiley \& Sons},
	author = {Conrad, Frederick G. and Blair, Johnny},
	year = {2004},
	keywords = {Cognitive Interviewing, Protocol Analysis, Verbal Protocols, Verbal Reports}
},

﻿@incollection {demaio_cogiv_tech_2004,
title = {Do Different Cognitive Interview Techniques Produce Different Results?},
author = {DeMaio, Theresa J. and Landreth, Ashley},
publisher = {John Wiley \& Sons, Inc.},
%isbn = {9780471654728},
%url = {http://dx.doi.org/10.1002/0471654728.ch5},
doi = {10.1002/0471654728.ch5},
pages = {89--108},
keywords = {cognitive interview techniques, different results, research methods, results, research objectives},
booktitle = {Methods for Testing and Evaluating Survey Questionnaires},
	crossref = {presser_methods_book_2004},
year = {2004},
abstract = {In this chapter we conduct a systematic investigation to evaluate alternative methods of conducting cognitive interviews. We begin with a review of the literature pertaining to the cognitive interviewing method. Next, we discuss the research objectives of our experiment. Then we describe the research methods, including the three experimental treatments and supplemental data collection. Finally, we present the research results, followed by a discussion of the implications of the research and a concluding section.},
}
@techreport{goerman_adapting_2006,
	address = {Washington, {D.C.}},
	title = {Adapting Cognitive Interview Techniques for Use in Pretesting Spanish Language Survey Instruments},
	abstract = {Pretesting methods that are currently used in survey research to develop and improve survey questions have been evolving for the past 20 years. While there has been increased focus on issues related to multicultural and multilingual survey design in recent years (e.g. Harkness, Van de Vijver, and Mohler [eds.], 2003), there has been relatively little research on the appropriateness of specific pretesting methods with respondents from different cultural and/or linguistic groups. Previous research has shown that some respondents have a great deal of difficulty with common cognitive interview probes and techniques. English-speaking respondents with low educational levels have been shown to have difficulty with both paraphrasing and think aloud probes {(Willis}, 2005; Bickert \& Felcher, 1996; Wellens, 1994). Both Spanish and Chinesespeaking respondents have been shown to experience even greater difficulty with translated cognitive interview probes and techniques, including the use of think aloud, paraphrasing, process oriented probes, and meaning oriented probes {(Pan}, 2004;},
	number = {2006-3},
	institution = {{US} Census Bureau},
	author = {Goerman, L.},
	month = feb,
	year = {2006},
	keywords = {Cognitive Interviewing, Questionnaire Testing}
},

@article{knafl_analysis_2007,
	title = {The analysis and interpretation of cognitive interviews for instrument development},
	volume = {30},
	%issn = {0160-6891},
	%url = {http://www.ncbi.nlm.nih.gov/pubmed/17380524},
	doi = {10.1002/nur.20195},
	abstract = {Cognitive interviews assess respondents' understanding of questionnaire items and are increasingly used to improve instrument design. Although investigators have described the contributions of cognitive interviews for instrument development, few guidelines are available for analyzing data from cognitive interviews when they are used for that purpose. In this article we address the development and application of analytic strategies for summarizing, interpreting, and using data from cognitive interviews that were conducted during the process of creating a measure of parental management of childhood chronic conditions. We discuss the contribution of cognitive interviews to establishing content validity and address the importance of developing standardized guidelines for analyzing and interpreting cognitive interviews in order to maximize their usefulness for instrument development.},
	number = {2},
	journal = {Research in Nursing \& Health},
	author = {Knafl, Kathleen and Deatrick, Janet and Gallo, Agatha and Holcombe, Gwynne and Bakitas, Marie and Dixon, Jane and Grey, Margaret},
	month = apr,
	year = {2007},
	note = {{PMID:} 17380524},
	keywords = {Cognitive Interviewing, Questionnaires, Research Design},
	pages = {224--234}
},

@article{memon_cognitive_1991,
	title = {The cognitive interview: Its origins, empirical support, evaluation and practical implications},
	volume = {1},
	%issn = {1099-1298},
	shorttitle = {The cognitive interview},
	%url = {http://onlinelibrary.wiley.com/doi/10.1002/casp.2450010405/abstract},
	doi = {10.1002/casp.2450010405},
	abstract = {This paper provides a background to current research on the cognitive interview {(CI)}, which is a set of cognitive retrieval techniques designed to facilitate memory search (for example, via reinstatement of contextual cues). One of the principal aims of this research is to identify and develop techniques which police investigators can themselves use. A series of studies were conducted at the University of California, Los Angeles, using police officers as interviewers and students, non-students and children as witnesses to realistic crimes. In all studies the {CI} elicited significantly more correct information with no apparent increase in errors or confabulations. The {CI} has been tested in a field study involving police officers in Florida. This paper will critically review this research, as well as more recent unpublished work including {CI} studies conducted in Germany and the {UK.} Some important modifications of the original {CI} procedure are described, and there is a theoretical discussion and explanation of the various components of the {CI} procedure. Finally, we will consider applications of the {CI} in clinical and organizational settings.},
	number = {4},
	journal = {Journal of Community \& Applied Social Psychology},
	author = {Memon, Amina and Bull, Ray},
	month = nov,
	year = {1991},
	keywords = {cognitive, Cognitive Interviewing, Memory, mnemonics, Police interview, retrieval, Survey Research},
	pages = {291--307}
},

@article{memon_cognitive_2010,
	title = {The Cognitive Interview: A {Meta-Analytic} Review and Study Space Analysis of the Past 25 Years},
	volume = {16},
	%issn = {1076-8971},
	shorttitle = {{THE} {COGNITIVE} {INTERVIEW}},
	%url = {http://www.sciencedirect.com/science/article/pii/S1076897110600142},
	doi = {10.1037/a0020518},
	abstract = {The Cognitive Interview {(CI)} is a well-established protocol for interviewing witnesses. The current article presents a study space analysis of laboratory studies of the {CI} together with an empirical meta-analysis summarizing the past 25 years of research. The study space comprises 57 published articles (65 experiments) on the {CI}, providing an assessment of the boundary conditions underlying the analysis and application of this interview protocol. The current meta-analysis includes 46 published articles, including 20 articles published since the last meta-analysis conducted a decade earlier {(Köhnken}, Milne, Memon, \&amp; Bull, 1999). Reassuringly for practitioners, the findings of the original meta-analysis were replicated with a large and significant increase in correct details and a small increase in errors. In addition we found that there were no differences in the rate at which details are confabulated. Importantly, the effect sizes were unaffected by the inclusion of recent studies using modified versions of the {CI.} The {CI} appeared to benefit older adult witnesses even more than younger adults. We highlight trends and gaps in research and discuss how our findings can inform policy and training decisions.},
	number = {4},
	journal = {Psychology, Public Policy, and Law},
	author = {Memon, Amina and Meissner, Christian A. and Fraser, Joanne},
	month = nov,
	year = {2010},
	keywords = {Cognitive Interviewing, eyewitness memory, meta-analysis, review},
	pages = {340--372}
},

@article{sasaki_recipient_2003,
	title = {Recipient Orientation in Verbal Report Protocols: Methodological Issues in Concurrent {Think-Aloud}},
	volume = {22},
	number = {1},
	journal = {Second Language Studies},
	author = {Sasaki, Tomomi},
	year = {2003},
	keywords = {Cognitive Interviewing, Protocol Analysis, Recipient Design, Recipient Orientation, Verbal Protocols},
	pages = {1--54}
},

@incollection{swain_verbal_2006,
	title = {Verbal protocols: What does it mean for research to use speaking as a data collection tool},
	shorttitle = {Verbal protocols},
	booktitle = {Inference and Generalizability in Applied Linguistics},
	publisher = {John Benjamins},
	author = {Swain, Merrill},
	year = {2006},
	keywords = {Cognitive Interviewing, Protocol Analysis, Verbal Protocols}
}
@book{tourangeau_psychology_2000,
	title = {The Psychology of Survey Response},
	%isbn = {9780521576291},
	abstract = {Drawing on classic and modern research from cognitive psychology, social psychology, and survey methodology, this book examines the psychological roots of survey data, how survey responses are formulated, and how seemingly unimportant features of the survey can affect the answers obtained. Topics include the comprehension of survey questions, the recall of relevant facts and beliefs, estimation and inferential processes people use to answer survey questions, the sources of the apparent instability of public opinion, the difficulties in getting responses into the required format, and distortions introduced into surveys by deliberate misreporting.},
	publisher = {Cambridge University Press},
	author = {Tourangeau, Roger and Rips, Lance J. and Rasinski, Kenneth A.},
	month = mar,
	year = {2000},
	keywords = {Cognitive Interviewing, Language Arts \& Disciplines / Communication Studies, Psychology / General, Psychology / Personality, Psychology / Reference, Psychology / Research \& Methodology, Psychology / Social Psychology, Public opinion polls, Public opinion polls - Evaluation, Public opinion polls/ Evaluation, Question Design, Social Science / Methodology, Social Science / Statistics, Social surveys, Social surveys - Psychological aspects, Social surveys/ Psychological aspects, Surveys}
},

@inproceedings{willis_use_2005,
	title = {The use of cognitive interviewing to evaluate translated survey questions: Lessons learned},
	shorttitle = {The use of cognitive interviewing to evaluate translated survey questions},
	abstract = {Methods for the development and pretesting of survey questions in languages other than English are undergoing significant evolution. In particular, researchers are increasingly interested in adapting pretesting methods such as cognitive interviewing and behavior coding. It is not a simple matter, however, to apply these methods in the cross-cultural domain. In particular, extension to multiple languages poses particular challenges in terms of staffing, interpretation of results, and data analysis. We review three projects that applied cognitive interviewing to assess cross-cultural equivalence of health questions across English, Spanish, and Asian languages. Based on this variety of experiences we present selected results indicating how cognitive interviewing can be used to make conclusions about the functioning of survey instruments across languages, and make recommendations concerning future practice in this area.},
	booktitle = {Proceedings of the Federal Committee on Statistical Methodology Research conference. November 14-16, 2005},
	author = {Willis, Gordon and Lawrence, Deirdre and Thompson, Fran and Kudela, Martha and Levin, Kerry and Miller, Kristen},
	year = {2005},
	keywords = {Cognitive Interviewing, Cross-cultural research, Question Translation, Translation}
},

@misc{willis_cognitive_1999,
	title = {Cognitive Interviewing: A {"How} To" Guide},
	publisher = {Research Triangle Institute},
	author = {Willis, Gordon B.},
	year = {1999},
	keywords = {Cognitive Interviewing}
}
@inproceedings{conrad_verbal_1999,
	address = {Washington  {D.C.}},
	title = {Verbal Reports are Data! A Theoretical Approach to Cognitive Interviews},
	abstract = {The use of verbal reports to pretest questionnaires (cognitive interviews) is the most tangible outcome to date of the dialogue between cognitive psychology and survey methodology. Cognitive interviews are a standard survey pretesting tool yet they rarely exploit the theory and body of knowledge about verbal report methods. For example it is believed that if people are not aware of a thought process, they cannot verbalize it. In addition, there is evidence that verbalizing certain processes can affect the process being reported. When these are overlooked, it threatens the validity of verbal reports. We have developed a two part technique for collecting and analyzing verbal reports in cognitive interviews that takes this into account. One part concerns collecting verbal reports - the administration of cognitive interviews. The second part concerns the analysis and interpretation the verbal reports. In the data collection part, cognitive interviewers use certain generic probes when a verbalization indicates the respondent is aware, of but has not reported, useful information. In the interpretation and analysis part, coders assign segments of the verbal reports to a problem taxonomy in which a set of problem classes can be occur throughout the stages of the response process. We advocate using an approach like this to increase the validity and objectivity of cognitive interview data. Preliminary data suggests that it is promising.},
	booktitle = {Proceedings of the Federal Committee on Statistical Methodology Research Conference},
	author = {Conrad, Frederick and Blair, Johnny and Tracy, Elena},
	year = {1999},
	keywords = {Cognitive Interviewing, Protocol Analysis, Verbal Reports}
}